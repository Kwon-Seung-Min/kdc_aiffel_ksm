{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac580b4",
   "metadata": {},
   "source": [
    "# ğŸ˜» ë°ì´í„° ì—”ì§€ë‹ˆì–´ë¥¼ ìœ„í•œ íŒŒì´ì¬ ì²«ê±¸ìŒ ğŸ˜»\n",
    "## 20ì¥. RDD ì‹¤ìŠµ (MapReduce ì‹¤ìŠµ : project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e90fe",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91bbdb9",
   "metadata": {},
   "source": [
    "## 1) Word Counter êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c19bf8",
   "metadata": {},
   "source": [
    "MapReduce ê°œë…ì„ ì²˜ìŒ ë°°ìš¸ ë•Œ í•­ìƒ ë‹¤ë£¨ê²Œ ë˜ëŠ” Word Counterë¥¼ êµ¬í˜„í•˜ëŠ” ë¬¸ì œë¥¼, ìŠ¤íŒŒí¬ RDD í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í•´ê²°í•´ ë³´ì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953799d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/07/29 04:54:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/29 04:54:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/07/29 04:54:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('b', 1),\n",
       " ('i', 1),\n",
       " ('l', 1),\n",
       " ('s', 1),\n",
       " ('r', 1),\n",
       " ('e', 2),\n",
       " ('a', 1),\n",
       " ('u', 2),\n",
       " ('t', 2),\n",
       " ('f', 1),\n",
       " ('m', 1),\n",
       " ('o', 1),\n",
       " ('n', 1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "text = sc.parallelize('beautiful monster')\n",
    "\n",
    "# map í•¨ìˆ˜ë¥¼ ì ìš©í•œ RDD êµ¬í•˜ê¸°\n",
    "text_1 = text.filter(lambda x: x != \" \")\n",
    "text_2 = text_1.map(lambda x:(x, 1))\n",
    "\n",
    "#reduceByKey í•¨ìˆ˜ë¥¼ ì ìš©í•œ Word Counter ì¶œë ¥\n",
    "word_count = text_2.reduceByKey(lambda accum, n: accum + n)  \n",
    "word_count.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4500e",
   "metadata": {},
   "source": [
    "## 2) Titanic ë°ì´í„° ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c6211e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('survived', '0'),\n",
       "  ('sex', 'male'),\n",
       "  ('age', '22.0'),\n",
       "  ('n_siblings_spouses', '1'),\n",
       "  ('parch', '0'),\n",
       "  ('fare', '7.25'),\n",
       "  ('class', 'Third'),\n",
       "  ('deck', 'unknown'),\n",
       "  ('embark_town', 'Southampton'),\n",
       "  ('alone', 'n')],\n",
       " [('survived', '1'),\n",
       "  ('sex', 'female'),\n",
       "  ('age', '38.0'),\n",
       "  ('n_siblings_spouses', '1'),\n",
       "  ('parch', '0'),\n",
       "  ('fare', '71.2833'),\n",
       "  ('class', 'First'),\n",
       "  ('deck', 'C'),\n",
       "  ('embark_town', 'Cherbourg'),\n",
       "  ('alone', 'n')],\n",
       " [('survived', '1'),\n",
       "  ('sex', 'female'),\n",
       "  ('age', '26.0'),\n",
       "  ('n_siblings_spouses', '0'),\n",
       "  ('parch', '0'),\n",
       "  ('fare', '7.925'),\n",
       "  ('class', 'Third'),\n",
       "  ('deck', 'unknown'),\n",
       "  ('embark_town', 'Southampton'),\n",
       "  ('alone', 'y')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Transformations ìŠ¤í…ì—ì„œ CSV íŒŒì¼ì„ ë¡œë”©í–ˆë˜ ë‚´ì—­ (Titanic ë°ì´í„°ì…ë‹ˆë‹¤.)\n",
    "csv_path = os.getenv('HOME')+'/data/train.csv'\n",
    "csv_data_0 = sc.textFile(csv_path)\n",
    "csv_data_1 = csv_data_0.filter(lambda line: len(line)>1).map(lambda line: line.split(\",\"))   \n",
    "columns = csv_data_1.take(1)\n",
    "csv_data_2 = csv_data_1.filter(lambda line: line[0].isdecimal())\n",
    "csv_data_3 = csv_data_2.map(lambda line: [(columns[0][i], linedata) for i, linedata in enumerate(line)])\n",
    "\n",
    "csv_data_3.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba191a",
   "metadata": {},
   "source": [
    "íƒ€ì´íƒ€ë‹‰ í˜¸ì—ì„œ ìƒì¡´ìì™€ ì‚¬ë§ìì˜ í‰ê· ì—°ë ¹ì„ êµ¬í•´ ë³´ì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16588ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì¡´ì í‰ê·  ì—°ë ¹: 29.110411522633743\n",
      "ì‚¬ë§ì í‰ê·  ì—°ë ¹: 29.9609375\n"
     ]
    }
   ],
   "source": [
    "# csv_data_3ì„ ê°€ê³µí•˜ì—¬ ìƒì¡´ì, ì‚¬ë§ìì˜ ì—°ë ¹ ì´í•©ê³¼ ì‚¬ëŒ ìˆ˜ë¥¼ ê°ê° êµ¬í•´ ë´…ì‹œë‹¤. \n",
    "# ì´í›„ ê°ê°ì˜ ë°ì´í„°ë¡œë¶€í„° ìƒì¡´ìì™€ ì‚¬ë§ìì˜ í‰ê·  ì—°ë ¹ì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "# ìƒì¡´ìì™€ ì‚¬ë§ìì˜ ì—°ë ¹ ì´í•© êµ¬í•˜ê¸°\n",
    "csv_data_4 = csv_data_3.map(lambda line:(line[0][1], line[2][1]))   # (ìƒì¡´ì—¬ë¶€, ì—°ë ¹)\n",
    "age_sum_data = csv_data_4.reduceByKey(lambda accum, age: float(accum) + float(age))  \n",
    "age_sum = age_sum_data.collect()\n",
    "\n",
    "# ìƒì¡´ìì™€ ì‚¬ë§ìì˜ ì‚¬ëŒ ìˆ˜ êµ¬í•˜ê¸°\n",
    "csv_data_5 = csv_data_3.map(lambda line:(line[0][1], 1))\n",
    "survived_data = csv_data_5.reduceByKey(lambda accum, count: int(accum) + int(count)) \n",
    "survived_count = survived_data.collect()\n",
    "\n",
    "age_sum_dict = dict(age_sum)\n",
    "survived_dict = dict(survived_count)\n",
    "avg_age_survived = age_sum_dict['1']/survived_dict['1']\n",
    "print('ìƒì¡´ì í‰ê·  ì—°ë ¹:' ,avg_age_survived)\n",
    "avg_age_died = age_sum_dict['0']/survived_dict['0']\n",
    "print('ì‚¬ë§ì í‰ê·  ì—°ë ¹:' ,avg_age_died)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
